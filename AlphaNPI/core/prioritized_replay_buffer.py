import numpy as np

class PrioritizedReplayBuffer():
    '''
    This class represents a replay buffer memory in which traces generated by the MCTS are stored.
    '''

    def __init__(self, max_length, task_ids, p1=0.8):
        self.task_ids = task_ids
        self.memory_task = dict((task_id, {0: [], 1: []}) for task_id in self.task_ids)
        self.stack = []
        self.max_length = max_length
        self.p1 = p1

    def get_memory_length(self):
        return len(self.stack)

    def append_trace(self, trace):
        '''
        Add a newly generated execution trace to the memory buffer.

        Args:
            trace: a sequence of [(e_0, i_0, (h_0, c_0), pi_0, r_0), ... , (e_T, i_T, (h_T, c_T), pi_T, r_T)]
        '''
        for tuple in trace:
            reward = 0 if tuple[4] <= 0.0 else 1
            if len(self.stack) >= self.max_length:
                t_id = self.stack[0][1]
                r = 0 if self.stack[0][4] <= 0.0 else 1
                del self.memory_task[t_id][r][0]
                del self.stack[0]
            task_id = tuple[1]
            self.memory_task[task_id][reward].append(tuple)
            self.stack.append(tuple)

    def _sample_sub_batch(self, batch_size, memory):
        indices = np.arange(len(memory))
        sampled_indices = np.random.choice(indices, size=batch_size, replace=(batch_size > len(memory)))
        batch = [[], [], [], [], []]
        for i in sampled_indices:
            for k in range(5):
                batch[k].append(memory[i][k])
        return batch

    def sample_batch(self, batch_size):
        '''
        Sample in the memory a batch of experience.

        Args:
            batch_size: the batch size

        Returns:
            a list [batch of e_t, batch of i_t, batch of (h_t, c_t), batch of pi_t, batch of r_t]
        '''
        memory_0 = []
        memory_1 = []
        for task_id in self.memory_task:
            if len(self.memory_task[task_id][1]) > 0:
                memory_0 += self.memory_task[task_id][0]
                memory_1 += self.memory_task[task_id][1]

        if len(memory_0) == 0 and len(memory_1) == 0:
            return None
        elif len(memory_1) > 0 and len(memory_0) == 0:
            batch = self._sample_sub_batch(batch_size, memory_1)
        elif len(memory_0) > 0 and len(memory_1) == 0:
            batch = self._sample_sub_batch(batch_size, memory_0)
        else:
            buffer_binomial_distrib = np.random.binomial(1, self.p1, batch_size)
            sub_batch_r1_size = sum(buffer_binomial_distrib)
            sub_batch_r0_size = batch_size - sub_batch_r1_size
            assert sub_batch_r1_size+sub_batch_r0_size == batch_size, 'problem with batch sizes!'
            batch = self._sample_sub_batch(sub_batch_r1_size, memory_1)
            batch += self._sample_sub_batch(sub_batch_r0_size, memory_0)

        return batch if batch else None

    def empty_memory(self):
        '''
        Empty the replay memory.
        '''
        self.memory_task = dict((task_id, {0: [], 1: []}) for task_id in self.task_ids)
        self.stack = []
